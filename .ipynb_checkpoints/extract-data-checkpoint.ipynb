{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "In this notebook, I'll extract 10% of the game plays to use them for training neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from pathlib import Path\n",
    "\n",
    "from nflutils.dataprep import *\n",
    "\n",
    "import glob\n",
    "\n",
    "SEED = 19951204\n",
    "CREATE_FRAMES_DF = True\n",
    "EXTRACT_FRAMES = False\n",
    "VIEWS = [\"Sideline\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LS = !ls\n",
    "IS_KAGGLE = 'init.sh' not in LS\n",
    "IS_KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if IS_KAGGLE:\n",
    "    # Read in data files\n",
    "    BASE_DIR = Path(\"../input/nfl-player-contact-detection\")\n",
    "    OUT_DIR = Path(\"/kaggle/working/\")\n",
    "else:\n",
    "    BASE_DIR = Path(\"nfl-player-contact-detection\")\n",
    "    OUT_DIR = Path(\"nfl-player-contact-detection/frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Labels and sample submission\n",
    "labels = pd.read_csv(BASE_DIR/\"train_labels.csv\", parse_dates=[\"datetime\"])\n",
    "\n",
    "ss = pd.read_csv(BASE_DIR/\"sample_submission.csv\")\n",
    "\n",
    "# Player tracking data\n",
    "tr_tracking = pd.read_csv(\n",
    "    BASE_DIR/\"train_player_tracking.csv\", parse_dates=[\"datetime\"]\n",
    ")\n",
    "te_tracking = pd.read_csv(\n",
    "    BASE_DIR/\"test_player_tracking.csv\", parse_dates=[\"datetime\"]\n",
    ")\n",
    "\n",
    "# Baseline helmet detection labels\n",
    "tr_helmets = pd.read_csv(BASE_DIR/\"train_baseline_helmets.csv\")\n",
    "te_helmets = pd.read_csv(BASE_DIR/\"test_baseline_helmets.csv\")\n",
    "\n",
    "# Video metadata with start/stop timestamps\n",
    "tr_video_metadata = pd.read_csv(\n",
    "    BASE_DIR/\"train_video_metadata.csv\",\n",
    "    parse_dates=[\"start_time\", \"end_time\", \"snap_time\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_combo = compute_distance(labels, tr_tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Fold 1:\n",
      "Fold 2:\n",
      "Fold 3:\n",
      "Fold 4:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "kf = GroupKFold()\n",
    "kf_dict = {}\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(tr_video_metadata, None, tr_video_metadata['game_key'])):\n",
    "    print(f\"Fold {i}:\")\n",
    "    kf_dict[i] = {'train_games': list(tr_video_metadata.iloc[train_index].game_play.unique()),\n",
    "                  'val_games': list(tr_video_metadata.iloc[test_index].game_play.unique())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should save the validation data games in order to use them further on during validation in different strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('kf_dict', 'wb') as f:\n",
    "    pickle.dump(kf_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('kf_dict', 'rb') as f:\n",
    "    kf_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's extract the validation set as a starter. I'll extract from only sideline view for starters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59904c30d29948a98d4c280eec461dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import subprocess, os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "val_games = kf_dict[0]['val_games']\n",
    "\n",
    "val_game_plays = tr_video_metadata.query('game_key in @val_games').game_play\n",
    "\n",
    "g_paths = []\n",
    "\n",
    "views_regex = '|'.join(VIEWS)\n",
    "\n",
    "for g in tqdm(val_game_plays):\n",
    "    paths = glob.glob(f'{(BASE_DIR/\"train\"/g).as_posix()}_[{views_regex}]*')\n",
    "    g_paths.extend(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if EXTRACT_FRAMES:\n",
    "    for g_path in tqdm(g_paths[:4]):\n",
    "        game_play = g_path.split('/')[-1].split('/')[-1][:-4]\n",
    "        (OUT_DIR/'validation'/game_play).mkdir(parents=True, exist_ok=True)\n",
    "        # print(\"mkdir -p $OUT_DIR/validation/$game_play && chmod 777 $OUT_DIR/validation/$game_play\")\n",
    "        # Source: https://www.kaggle.com/code/zzy990106/nfl-2-5d-cnn-baseline-inference\n",
    "        !echo \"ffmpeg -i $g_path -q:v 2 -f image2 $OUT_DIR/validation/$game_play/frame-%04d.jpg -hide_banner -loglevel error\"\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<s>Now let's extract 10% of train game_plays</s>\n",
    "\n",
    "Since I'm only creating the dataframe now, I'll use the time to create the dataframe needed for all subsequent training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_games = kf_dict[0]['train_games']\n",
    "\n",
    "train_game_plays = tr_video_metadata.query('game_key in @train_games').game_play#.sample(frac=0.1, replace=False, random_state=SEED).game_play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if EXTRACT_FRAMES:\n",
    "    !mkdir -p $OUT_DIR/train\n",
    "    !chmod 777 $OUT_DIR/train\n",
    "\n",
    "    for g in train_game_plays:\n",
    "        g_paths = !ls $BASE_DIR/train/$g*\n",
    "        for g_path in g_paths:\n",
    "            game_play = g_path.split('/')[-1].split('/')[-1][:-4]\n",
    "            !mkdir -p $OUT_DIR/train/$game_play && chmod 777 $OUT_DIR/train/$game_play\n",
    "            !ffmpeg -i \"$g_path\" -q:v 2 -f image2 \"$OUT_DIR/train/$game_play/frame-%04d.jpg\" -hide_banner -loglevel error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 s, sys: 3.66 s, total: 15.3 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_combo_2 = merge_tracking_and_helmets(df_combo.query('distance <= 1.6'), tr_helmets)\n",
    "df_combo_2 = calc_two_players_helmets_center(df_combo_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_2 = df_combo_2.query(\"view != 'Endzone2'\")\n",
    "df_combo_2 = df_combo_2[~df_combo_2.view.isna()]\n",
    "df_combo_2 = df_combo_2[~df_combo_2.left_2.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo_2.to_parquet(\"df_combo_with_helmets.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo.to_parquet(\"df_combo.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
