{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147354c6-738a-491f-8979-ed2dc3a270b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 4121995\n",
    "    undersample_no_contact = True\n",
    "    img_size = 224\n",
    "    model = 'resnet18'  \n",
    "    epochs = 20\n",
    "    train = False\n",
    "    valid = False\n",
    "    infer = True\n",
    "    thresh = 0.64\n",
    "    dist_thresh = 2\n",
    "    model_name = 'rgb-bbox-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d2aa948-9f2e-49a6-a1d5-21f5e8bf0d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LS = !ls\n",
    "IS_KAGGLE = 'init.sh' not in LS\n",
    "IS_KAGGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14df5317-2a53-4068-b7c5-e75c0acfc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    sys.path.append('/kaggle/input/timm-0-6-9/pytorch-image-models-master')\n",
    "    CFG.frames_path = ''\n",
    "    CFG.utils_path = '/kaggle/input/nflutils'\n",
    "    \n",
    "    sys.path.insert(0, '../input/nflutils')\n",
    "    !mkdir -p nflutils\n",
    "    !cp ../input/nflutils/*.py nflutils/\n",
    "    \n",
    "else:\n",
    "    CFG.frames_path = 'frames/content/work/frames/train'\n",
    "    CFG.utils_path = 'nflutils'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd7ba203-e657-413a-a8ce-076fa2bc3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import pickle\n",
    "import timm\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from nflutils.dataprep import *\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "952b7b10-0799-4db8-8f77-12d63856c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_KAGGLE:\n",
    "    BASE_DIR = Path(\"../input/nfl-player-contact-detection\")\n",
    "    OUT_DIR = Path(\"/kaggle/working/\")\n",
    "else:\n",
    "    BASE_DIR = Path(\"nfl-player-contact-detection\")\n",
    "    OUT_DIR = Path(\"nfl-player-contact-detection/frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3265377b-9600-4bdd-b69b-ef260363f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combo = pd.read_parquet(CFG.utils_path+'/df_combo.parquet')\n",
    "df_combo_with_helmets = pd.read_parquet(CFG.utils_path+'/df_tracking_helmets_below_2.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "225a78e5-c935-4b5a-8bb0-c0939ec4ce9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, matthews_corrcoef\n",
    "import functools\n",
    "\n",
    "@functools.lru_cache(maxsize=1250)\n",
    "def _get_frame(path):\n",
    "    frame = cv2.imread(path)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    return frame\n",
    "\n",
    "def add_helmets(frame, row):\n",
    "    frame = frame.copy()\n",
    "    frame = cv2.rectangle(frame, \n",
    "                          (int(row.left_1), int(row.top_1)),\n",
    "                          (int(row.left_1+row.width_1), int(row.top_1+row.height_1)),\n",
    "                          (255, 0, 0), 2)\n",
    "    \n",
    "    if not np.isnan(row.left_2):\n",
    "        frame = cv2.rectangle(frame, \n",
    "                              (int(row.left_2), int(row.top_2)),\n",
    "                              (int(row.left_2+row.width_2), int(row.top_2+row.height_2)),\n",
    "                              (255, 0, 0), 2)\n",
    "    return frame\n",
    "\n",
    "\n",
    "class NFLFrameDataset(Dataset):\n",
    "    def __init__(self, frames_df, transform=None, crop_size=256, helmets=True):\n",
    "        self.frames_df = frames_df\n",
    "        self.helmets = helmets\n",
    "        self.crop_size = crop_size\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.frames_df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.frames_df.iloc[idx]\n",
    "        frame = self.get_frame(row.path)\n",
    "        if self.helmets:\n",
    "            frame = add_helmets(frame, row)\n",
    "            # frame = add_helmet_heatmap(frame, row)\n",
    "            \n",
    "        frame = crop_frame(frame, row.center_x, row.center_y, self.crop_size)\n",
    "        if self.transform is not None:\n",
    "            frame = self.transform(image=frame)['image']\n",
    "        return frame, row.contact\n",
    "    \n",
    "    def get_frame(self, path):\n",
    "        return _get_frame(path)\n",
    "    \n",
    "def crop_frame(frame, x, y, size):\n",
    "    size = size // 2\n",
    "    \n",
    "    if y-size < 0:\n",
    "        min_y = 0\n",
    "        max_y = min_y + 2*size\n",
    "        \n",
    "    elif y+size > 719:\n",
    "        min_y = 719 - 2*size\n",
    "        max_y = 719\n",
    "        \n",
    "    else:\n",
    "        min_y = y - size\n",
    "        max_y = y + size\n",
    "    \n",
    "    if x-size < 0:\n",
    "        min_x = 0\n",
    "        max_x = min_x + 2*size\n",
    "        \n",
    "    elif x+size > 1279:\n",
    "        min_x = 1279 - 2*size\n",
    "        max_x = 1279\n",
    "        \n",
    "    else:\n",
    "        min_x = x - size\n",
    "        max_x = x + size\n",
    "        \n",
    "    cropped_frame = frame[int(min_y):int(max_y), \n",
    "                          int(min_x):int(max_x), :]\n",
    "    return cropped_frame\n",
    "    \n",
    "def visualize_batch(batch, means, stds):\n",
    "    \"\"\"\n",
    "    Visualize a batch of image data using Matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "        - batch_tensor (torch.Tensor): A batch of image data in the shape (batch_size, channels, height, width).\n",
    "        - means (tuple): A tuple of means for each channel in the image data.\n",
    "        - stds (tuple): A tuple of standard deviations for each channel in the image data.\n",
    "    \"\"\"\n",
    "    # Make a copy of the batch tensor so that we don't modify the original data\n",
    "    batch_tensor = batch[0].clone()\n",
    "    \n",
    "    # De-normalize the data using the means and stds\n",
    "    batch_tensor = batch_tensor * torch.tensor(stds, dtype=batch_tensor.dtype).view(3, 1, 1) + torch.tensor(means, dtype=batch_tensor.dtype).view(3, 1, 1)\n",
    "    \n",
    "    # Convert the data to numpy and transpose it to (batch_size, height, width, channels)\n",
    "    batch_np = batch_tensor.numpy().transpose(0, 2, 3, 1)\n",
    "    \n",
    "    # Plot the images\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(batch_np.shape[0]):\n",
    "        plt.subplot(batch_np.shape[0] // 5 + 1, 5, i + 1)\n",
    "        plt.imshow(batch_np[i])\n",
    "        plt.title(['no contact', 'contact'][batch[1][i].item()])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "def smooth_predictions(val_df, center, ws):\n",
    "    val_df_new = pd.DataFrame()\n",
    "    for group, group_df in tqdm(val_df.groupby(['game_play', 'nfl_player_id_1', 'nfl_player_id_2', 'view'])):\n",
    "        group_df = group_df.sort_values('frame')\n",
    "        for w in ws: \n",
    "            group_df[f'contact_pred_rolling_{w}'] = group_df.contact_pred.rolling(w, center=center).mean().bfill().ffill().fillna(0)\n",
    "        val_df_new = pd.concat([val_df_new, group_df])\n",
    "    return val_df_new\n",
    "\n",
    "def merge_combo_val(df_combo, val_df, pred_col='contact_pred_rolling'):\n",
    "    val_dist = df_combo[df_combo.game_play.isin(val_df.game_play.unique())].copy()\n",
    "\n",
    "    val_dist[\"distance\"] = val_dist[\"distance\"].fillna(99)  # Fill player to ground with 9    \n",
    "    val_dist_agg = val_dist.merge(val_df.groupby('contact_id', as_index=False)[pred_col].mean(), how='left', on='contact_id')\n",
    "    val_dist_agg = val_dist_agg.merge(val_df.groupby('contact_id', as_index=False)['thresh'].first(), how='left', on='contact_id')\n",
    "    \n",
    "    if pred_col != 'contact_pred':\n",
    "        val_dist_agg = val_dist_agg.merge(val_df.groupby('contact_id', as_index=False)['contact_pred'].mean(), how='left', on='contact_id')\n",
    "        \n",
    "    return val_dist_agg\n",
    "\n",
    "def get_matthews_corrcoef(val_dist_agg, pred_col='contact_pred_rolling', thresh=0.5):\n",
    "    out = np.where(val_dist_agg['contact_pred'].isna(),\n",
    "                   val_dist_agg['distance'] <= 1, \n",
    "                   val_dist_agg[pred_col] > val_dist_agg['thresh']).astype(int)\n",
    "    \n",
    "    return matthews_corrcoef(val_dist_agg['contact'], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ff5272c-1120-408a-85b0-20817f546eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf_dict = pickle.load(open('kf_dict', 'rb'))\n",
    "val_games = kf_dict[0]['val_games']\n",
    "\n",
    "val_df = df_combo_with_helmets.query('game_play in @val_games').copy()\n",
    "val_df['frame'] = val_df['frame'].astype(int)\n",
    "val_df['path'] = val_df.apply(lambda x: get_frame_path(x, CFG.frames_path), axis=1)\n",
    "\n",
    "val_df.to_parquet(CFG.utils_path+'/val_df.parquet', index=False)\n",
    "\n",
    "val_df = pd.read_parquet(CFG.utils_path+'/val_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce09ab65-ec1e-4840-804d-6dba1b258989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/fastai/learner.py:58: UserWarning: Saved filed doesn't contain an optimizer state.\n",
      "  elif with_opt: warn(\"Saved filed doesn't contain an optimizer state.\")\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "set_seed(42, True)\n",
    "name = 'rgb-bbox-1'\n",
    "seed = 42\n",
    "bs = 64\n",
    "channels = 3\n",
    " \n",
    "means = [0.485, 0.456, 0.406]\n",
    "stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=means[:channels], std=stds[:channels]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transform2 = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=1),\n",
    "        A.Normalize(mean=means[:channels], std=stds[:channels]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_ds = NFLFrameDataset(val_df, transform=val_transform, crop_size=256)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=bs, shuffle=False, num_workers=8, pin_memory=True,\n",
    ")\n",
    "\n",
    "test_ds2 = NFLFrameDataset(val_df, transform=val_transform2, crop_size=256)\n",
    "\n",
    "test_loader2 = DataLoader(\n",
    "    test_ds2, batch_size=bs, shuffle=False, num_workers=8, pin_memory=True,\n",
    ")\n",
    "\n",
    "mini_ds = NFLFrameDataset(val_df.iloc[:bs], transform=val_transform, crop_size=256)\n",
    "\n",
    "mini_loader = DataLoader(\n",
    "    mini_ds, batch_size=bs, shuffle=False, num_workers=2, pin_memory=True,\n",
    ")\n",
    "\n",
    "data = DataLoaders(test_loader, test_loader)\n",
    "\n",
    "model, model_info = create_timm_model('convnext_tiny', 2, n_in=3)\n",
    "\n",
    "learn = Learner(data, model, CrossEntropyLossFlat(), metrics=[accuracy, MatthewsCorrCoef(), Recall(), Precision(), F1Score()],\n",
    "                cbs=[\n",
    "                    # WandbCallback(log_preds=False, seed=seed),\n",
    "                    # SaveModelCallback(monitor='matthews_corrcoef', fname=name)\n",
    "                ]\n",
    "               ).to_fp16()\n",
    "\n",
    "learn = learn.load(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2693059-0fc9-4f1d-a413-13eea683130a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds1, _ = learn.get_preds(dl=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50065d11-990e-4bce-b931-e59c8def4d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds2, _ = learn.get_preds(dl=test_loader2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a653bef2-ee69-41b7-81ef-7b5ad3538673",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['contact_pred1'] = preds1[:, 1]\n",
    "val_df['contact_pred2'] = preds2[:, 1]\n",
    "\n",
    "val_df.to_csv(f'{name}_tta.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6832791d-2fb7-4fd4-b154-dab058a00745",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['contact_pred'] = 0.5*val_df.contact_pred1 + 0.5*val_df.contact_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33787b94-215d-47a3-90b4-a0a1a3d370d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eada3cbedab44d68d6a77ecfd3ac7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_df = smooth_predictions(val_df, ws=[30, 60], center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81e48c60-1fd6-4ce6-aaeb-3c77eb80119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df['contact_pred_rolling'] = np.where(val_df.nfl_player_id_2.notnull(), val_df[f'contact_pred_rolling_30'], val_df[f'contact_pred_rolling_60'])\n",
    "val_df['thresh'] = np.where(val_df.nfl_player_id_2.notnull(), 0.67, 0.477778)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc83c6fa-80bb-41c4-b7c5-afece57ebed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = val_df[(val_df.left_2.notnull()) | (val_df.nfl_player_id_2 == \"G\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c4eede1-372f-47f3-9f8c-a6f44a9e3930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7157499360798741"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = merge_combo_val(df_combo, tmp_df)\n",
    "get_matthews_corrcoef(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec6b190-5577-49e8-85d2-7e556087bf13",
   "metadata": {},
   "source": [
    "Not the best results, so let's rework the smoothing and thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70c3d3ea-b842-469c-9957-22cce00865ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8c7278f542466faaec67e976042564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_df = smooth_predictions(tmp_df, center=True, ws=np.arange(6, 62, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b52eb65-e55a-4aa9-bb05-d55feffbc660",
   "metadata": {},
   "outputs": [],
   "source": [
    "tried_configs = set()\n",
    "tried_configs.add(tuple({'1': 0, '2':1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "394d00dc-79b6-46cb-b0d7-fb7f0d27d75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5618c5315543f0be1aad7a50a6a9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m tmp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontact_pred_rolling\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(tmp_df\u001b[38;5;241m.\u001b[39mnfl_player_id_2\u001b[38;5;241m.\u001b[39mnotnull(), tmp_df[p_col], tmp_df[g_col])\n\u001b[1;32m     24\u001b[0m tmp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthresh\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(tmp_df\u001b[38;5;241m.\u001b[39mnfl_player_id_2\u001b[38;5;241m.\u001b[39mnotnull(), p_t, g_t)\n\u001b[0;32m---> 26\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_combo_val\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_combo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontact_pred_rolling\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m get_matthews_corrcoef(tmp)\n\u001b[1;32m     29\u001b[0m cols_results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mmerge_combo_val\u001b[0;34m(df_combo, val_df, pred_col)\u001b[0m\n\u001b[1;32m    119\u001b[0m val_dist \u001b[38;5;241m=\u001b[39m df_combo[df_combo\u001b[38;5;241m.\u001b[39mgame_play\u001b[38;5;241m.\u001b[39misin(val_df\u001b[38;5;241m.\u001b[39mgame_play\u001b[38;5;241m.\u001b[39munique())]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    121\u001b[0m val_dist[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m val_dist[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m99\u001b[39m)  \u001b[38;5;66;03m# Fill player to ground with 9    \u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m val_dist_agg \u001b[38;5;241m=\u001b[39m val_dist\u001b[38;5;241m.\u001b[39mmerge(\u001b[43mval_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontact_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpred_col\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontact_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    123\u001b[0m val_dist_agg \u001b[38;5;241m=\u001b[39m val_dist_agg\u001b[38;5;241m.\u001b[39mmerge(val_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontact_id\u001b[39m\u001b[38;5;124m'\u001b[39m, as_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthresh\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfirst(), how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontact_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred_col \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontact_pred\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/groupby/groupby.py:1965\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1965\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only_bool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only_bool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/groupby/groupby.py:1601\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1599\u001b[0m \u001b[38;5;66;03m# TypeError -> we may have an exception in trying to aggregate\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m \u001b[38;5;66;03m#  continue and exclude the block\u001b[39;00m\n\u001b[0;32m-> 1601\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_failures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_ser \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_mgr) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m   1604\u001b[0m     warn_dropping_nuisance_columns_deprecated(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), how)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/managers.py:1347\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[0;34m(self, func, ignore_failures)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1346\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1347\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m   1349\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/internals/blocks.py:402\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/groupby/groupby.py:1587\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1585\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray_func\u001b[39m(values: ArrayLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   1586\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1587\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maggregate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1591\u001b[0m         \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m         \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m         \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m         \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/groupby/ops.py:937\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    935\u001b[0m cy_op \u001b[38;5;241m=\u001b[39m WrappedCythonOp(kind\u001b[38;5;241m=\u001b[39mkind, how\u001b[38;5;241m=\u001b[39mhow)\n\u001b[0;32m--> 937\u001b[0m ids, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_info\u001b[49m\n\u001b[1;32m    938\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[1;32m    940\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m    941\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    946\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/properties.pyx:37\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/groupby/ops.py:834\u001b[0m, in \u001b[0;36mBaseGrouper.group_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgroup_info\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp], \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m--> 834\u001b[0m     comp_ids, obs_group_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_compressed_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m     ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(obs_group_ids)\n\u001b[1;32m    837\u001b[0m     comp_ids \u001b[38;5;241m=\u001b[39m ensure_platform_int(comp_ids)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/groupby/ops.py:862\u001b[0m, in \u001b[0;36mBaseGrouper._get_compressed_codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m compress_group_index(group_index, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort)\n\u001b[1;32m    861\u001b[0m ping \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroupings[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 862\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodes\u001b[49m, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(ping\u001b[38;5;241m.\u001b[39mgroup_index), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/groupby/grouper.py:622\u001b[0m, in \u001b[0;36mGrouping.codes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# _codes is set in __init__ for MultiIndex cases\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_codes\n\u001b[0;32m--> 622\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codes_and_uniques\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/_libs/properties.pyx:37\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/groupby/grouper.py:690\u001b[0m, in \u001b[0;36mGrouping._codes_and_uniques\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m         na_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 690\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouping_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m codes, uniques\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/algorithms.py:768\u001b[0m, in \u001b[0;36mfactorize\u001b[0;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    763\u001b[0m     codes, uniques \u001b[38;5;241m=\u001b[39m factorize_array(\n\u001b[1;32m    764\u001b[0m         values, na_sentinel\u001b[38;5;241m=\u001b[39mna_sentinel, size_hint\u001b[38;5;241m=\u001b[39msize_hint, na_value\u001b[38;5;241m=\u001b[39mna_value\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 768\u001b[0m     uniques, codes \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sort\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_sentinel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massume_unique\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    772\u001b[0m code_is_na \u001b[38;5;241m=\u001b[39m codes \u001b[38;5;241m==\u001b[39m na_sentinel\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dropna \u001b[38;5;129;01mand\u001b[39;00m code_is_na\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;66;03m# na_value is set based on the dtype of uniques, and compat set to False is\u001b[39;00m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;66;03m# because we do not want na_value to be 0 for integers\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/algorithms.py:1739\u001b[0m, in \u001b[0;36msafe_sort\u001b[0;34m(values, codes, na_sentinel, assume_unique, verify)\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1738\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m         sorter \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1740\u001b[0m         ordered \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mtake(sorter)\n\u001b[1;32m   1741\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1742\u001b[0m         \u001b[38;5;66;03m# Previous sorters failed or were not applicable, try `_sort_mixed`\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m         \u001b[38;5;66;03m# which would work, but which fails for special case of 1d arrays\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m         \u001b[38;5;66;03m# with tuples.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cols = tmp_df.columns[tmp_df.columns.str.contains('rolling')].to_list()[::2]\n",
    "\n",
    "cols_results = []\n",
    "tried_configs = set()\n",
    "\n",
    "for p_col in tqdm(cols):\n",
    "    for g_col in cols:\n",
    "        for p_t in np.linspace(0.3, 0.7, 5):\n",
    "            for g_t in np.linspace(0.3, 0.7, 5):\n",
    "        \n",
    "                result = {}\n",
    "\n",
    "                result['p_col'] = p_col\n",
    "                result['p_t'] = p_t\n",
    "                result['g_col'] = g_col\n",
    "                result['g_t'] = g_t\n",
    "                \n",
    "                if (p_col, p_t, g_col, g_t) in tried_configs:\n",
    "                    continue\n",
    "                else:\n",
    "                    tried_configs.add((p_col, p_t, g_col, g_t))\n",
    "                \n",
    "                tmp_df['contact_pred_rolling'] = np.where(tmp_df.nfl_player_id_2.notnull(), tmp_df[p_col], tmp_df[g_col])\n",
    "                tmp_df['thresh'] = np.where(tmp_df.nfl_player_id_2.notnull(), p_t, g_t)\n",
    "\n",
    "                tmp = merge_combo_val(df_combo, tmp_df, 'contact_pred_rolling')\n",
    "                result['score'] = get_matthews_corrcoef(tmp)\n",
    "\n",
    "                cols_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c509ea9e-e474-4aa5-bc91-27c02d9d43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cols_results).sort_values('score', ascending=False).iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3ca766-6619-49be-9853-0db08895e647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
